{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import floresta\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import UnigramTagger\n",
    "from nltk import DefaultTagger\n",
    "from nltk import BigramTagger\n",
    "import string\n",
    "\n",
    "def fill_new_corpus():\n",
    "    corpus = []\n",
    "    for sent in floresta.tagged_sents():\n",
    "        new_sent = []\n",
    "        for word in sent:\n",
    "            if word[0].lower() not in string.punctuation:\n",
    "                new_sent.append(word)\n",
    "        corpus.append(new_sent)\n",
    "    return corpus\n",
    "        \n",
    "def generate_tokenizer(corpus):\n",
    "    test = corpus\n",
    "    t0 = DefaultTagger(\"n\")\n",
    "    t1 = UnigramTagger(test, backoff=t0)\n",
    "    t2 = BigramTagger(test, backoff=t1)\n",
    "    return t2\n",
    "    \n",
    "def tokenizer_phrase(phrase, tagger):\n",
    "    tag_phrase = tagger.tag(phrase)\n",
    "    return tag_phrase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type some phrase here: O pé de manga está carregado este ano.\n"
     ]
    }
   ],
   "source": [
    "phrase = input('Type some phrase here: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = fill_new_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = generate_tokenizer(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_phrase = tokenizer_phrase(phrase.split(' '), tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', '>N+art'),\n",
       " ('pé', 'H+n'),\n",
       " ('de', 'H+prp'),\n",
       " ('manga', 'n'),\n",
       " ('está', 'P+v-fin'),\n",
       " ('carregado', 'CJT+v-pcp'),\n",
       " ('este', '>N+pron-det'),\n",
       " ('ano.', 'n')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
